{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Citation credit : By Chris McCormick and Nick Ryan https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ],
      "metadata": {
        "id": "j45fCGOhHStn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup environment and dependecies"
      ],
      "metadata": {
        "id": "ep9dZTm9Cxnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JKB3IGKCwd6",
        "outputId": "1f05bce8-1d3c-4cba-bc0f-8e1bd0c0d12c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install hugging face library\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhEwt7F5C9Ls",
        "outputId": "423e0e58-5317-4dba-9796-a8cb149efc07"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load datasets\n",
        "labeled = pd.read_csv(\"https://raw.githubusercontent.com/xxichlas/ep-nlp-sentiment-kebocorandata/main/labeled.csv\")\n",
        "unlabeled = pd.read_csv(\"https://raw.githubusercontent.com/xxichlas/ep-nlp-sentiment-kebocorandata/main/unlabeled.csv\")"
      ],
      "metadata": {
        "id": "H22fr7qUDVki"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview datasets"
      ],
      "metadata": {
        "id": "8m2yEqznD9ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wNyMOd6-EBJR",
        "outputId": "433c915f-5446-4757-a589-821b43f5dac8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                              tweet  tipe\n",
              "0             0  saran aktifasi sim card pakai nik hapus krna b...     0\n",
              "1             1  mau kata untuk gambar menteri kerja sim card s...     0\n",
              "2             2  pakai sim card paksa pakai ktp kkgiliran data ...     0\n",
              "3             3  ribut data sim card bocor lah dulu kampus data...     1\n",
              "4             4  jelas bisa ngatasin sendiri data ada perintah ...     1\n",
              "..          ...                                                ...   ...\n",
              "604         604  kominfo aku duga bocor data sim card adakemiripan     1\n",
              "605         605  kominfo bobol data registrasi sim card rasa pa...     1\n",
              "606         606  banyak milyar data sim card warga indonesia di...     1\n",
              "607         607     kominfo tindak lanjut duga bocor data sim card     1\n",
              "608         608  kominfo panggil seluruh operator seluler telko...     1\n",
              "\n",
              "[609 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c38ea9a-ac6f-4969-aa09-014275fe5c77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tipe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>saran aktifasi sim card pakai nik hapus krna b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>mau kata untuk gambar menteri kerja sim card s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>pakai sim card paksa pakai ktp kkgiliran data ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ribut data sim card bocor lah dulu kampus data...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>jelas bisa ngatasin sendiri data ada perintah ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>604</td>\n",
              "      <td>kominfo aku duga bocor data sim card adakemiripan</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>605</th>\n",
              "      <td>605</td>\n",
              "      <td>kominfo bobol data registrasi sim card rasa pa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606</th>\n",
              "      <td>606</td>\n",
              "      <td>banyak milyar data sim card warga indonesia di...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607</th>\n",
              "      <td>607</td>\n",
              "      <td>kominfo tindak lanjut duga bocor data sim card</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>608</td>\n",
              "      <td>kominfo panggil seluruh operator seluler telko...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>609 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c38ea9a-ac6f-4969-aa09-014275fe5c77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c38ea9a-ac6f-4969-aa09-014275fe5c77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c38ea9a-ac6f-4969-aa09-014275fe5c77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Fi-wFPszEECc",
        "outputId": "79558a61-6e0f-4a91-fe8d-21239d5b66ee"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                              tweet\n",
              "0             0  data sim card bocor media main blender menkomi...\n",
              "1             1  data sim card bocor media main blender menkomi...\n",
              "2             2  kemenkominfo investigasi bocor miliar data sim...\n",
              "3             3  kan kalian bikin atur beli sim card pakai nik ...\n",
              "4             4   kominfo bocor miliar data sim card olah pahlawan\n",
              "..          ...                                                ...\n",
              "343         343  miliar data daftar kartu sim telepon indonesia...\n",
              "344         344  buat regulasi daftar data kartu sim telepon ka...\n",
              "345         345  kait duga data sim bocor nyata tri kominfo mil...\n",
              "346         346  benar kominfo data sim bocor data duli lindung...\n",
              "347         347  milliar data registrasi kartu sim bocor lalu a...\n",
              "\n",
              "[348 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ca2a99e-c74c-4110-9935-3ef6f276afbb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>data sim card bocor media main blender menkomi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>data sim card bocor media main blender menkomi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>kemenkominfo investigasi bocor miliar data sim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>kan kalian bikin atur beli sim card pakai nik ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>kominfo bocor miliar data sim card olah pahlawan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>343</td>\n",
              "      <td>miliar data daftar kartu sim telepon indonesia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>344</td>\n",
              "      <td>buat regulasi daftar data kartu sim telepon ka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>345</td>\n",
              "      <td>kait duga data sim bocor nyata tri kominfo mil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>346</td>\n",
              "      <td>benar kominfo data sim bocor data duli lindung...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>347</td>\n",
              "      <td>milliar data registrasi kartu sim bocor lalu a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>348 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ca2a99e-c74c-4110-9935-3ef6f276afbb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ca2a99e-c74c-4110-9935-3ef6f276afbb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ca2a99e-c74c-4110-9935-3ef6f276afbb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get labeled data sets for the training later\n",
        "sentences = labeled.tweet.values\n",
        "labels = labeled.tipe.values"
      ],
      "metadata": {
        "id": "eUGKJ03qEEv3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization and Input Formatting"
      ],
      "metadata": {
        "id": "JYAthJ33Elrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert Tokenizer"
      ],
      "metadata": {
        "id": "lOKRwW3MEuKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "indobert_tweet = 'indolem/indobertweet-base-uncased'\n",
        "indobert_largep2 = 'indobenchmark/indobert-large-p2'\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-large-p2', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqyZmPBGEqiF",
        "outputId": "c8da4163-fe3d-4e5c-8ed7-db889b170e14"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgRb2KZ7EwiT",
        "outputId": "409bd93d-da40-48b8-fa41-70f82c49ff7d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  saran aktifasi sim card pakai nik hapus krna bahaya soal negara mampu lindung data rakyat nya\n",
            "Tokenized:  ['saran', 'aktif', '##asi', 'sim', 'card', 'pakai', 'nik', 'hapus', 'krna', 'bahaya', 'soal', 'negara', 'mampu', 'lindung', 'data', 'rakyat', 'nya']\n",
            "Token IDs:  [3386, 1786, 91, 3284, 5816, 2468, 7443, 5120, 25527, 5275, 1495, 664, 1085, 19861, 1006, 1829, 1107]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenized Datasets"
      ],
      "metadata": {
        "id": "hp-a9ZhnEzLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRqNayrUEx3E",
        "outputId": "4f298796-05da-411e-b2c2-4d531443cc67"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 65,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb2pRYrgFGLk",
        "outputId": "e1dfbce5-2f36-4724-b7ab-8070c7ea2036"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  saran aktifasi sim card pakai nik hapus krna bahaya soal negara mampu lindung data rakyat nya\n",
            "Token IDs: tensor([    2,  3386,  1786,    91,  3284,  5816,  2468,  7443,  5120, 25527,\n",
            "         5275,  1495,   664,  1085, 19861,  1006,  1829,  1107,     3,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wZo53AQWCw2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Validation Split"
      ],
      "metadata": {
        "id": "99Z_FLtbFI6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6EN140VFLU2",
        "outputId": "a3812675-3c1f-45a1-b766-070c13b3ba35"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  487 training samples\n",
            "  122 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "FR4j1xWgFOam"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Classification with Indo Bert"
      ],
      "metadata": {
        "id": "pW8sy91AFYc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Indobert and optimizers"
      ],
      "metadata": {
        "id": "lQ7CzLlXGD3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'indobenchmark/indobert-large-p2', # Use the 12-layer indobertmodel for tweet, uncased\n",
        "    num_labels = 3, # The number of output labels--3 for netral negatif positif classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhdBEH_XFauv",
        "outputId": "0423a9f0-2389-4718-da92-c782c649657c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-large-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ],
      "metadata": {
        "id": "EyrSbmv-kGin"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vgPuIObF3lv",
        "outputId": "d793bf15-d698-4435-ce93-dd9d32cbb87d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 5\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "oWygIbYNF_26"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train loop"
      ],
      "metadata": {
        "id": "a9kN8oXUGHlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "## Helper function for formatting elapsed times as `hh:mm:ss`\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "71dlE_75GIkP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "loss_values = []\n",
        "y_true_val=[]\n",
        "y_pred_val = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        if epoch_i==epochs-1:\n",
        "          y_pred_val.append(logits)\n",
        "          y_true_val.append(label_ids)\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSBDmd_iGUEH",
        "outputId": "325e5521-95e4-46ce-c96d-bcde80408066"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.64\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.54\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.46\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.51\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.54\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.60\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:01:53 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summary training procces"
      ],
      "metadata": {
        "id": "mVNcmWA0G2y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "0BwhgxE_G4OY",
        "outputId": "b04f4b35-fb15-469d-8c86-f4f1b381fe30"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.64         0.54           0.82       0:00:21         0:00:02\n",
              "2               0.37         0.46           0.84       0:00:21         0:00:02\n",
              "3               0.20         0.51           0.85       0:00:21         0:00:02\n",
              "4               0.12         0.54           0.86       0:00:21         0:00:02\n",
              "5               0.07         0.60           0.86       0:00:21         0:00:02"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19257290-6646-4982-a485-5441c1da9cdf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.64</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:00:21</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:00:21</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:00:21</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:00:21</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:00:21</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19257290-6646-4982-a485-5441c1da9cdf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19257290-6646-4982-a485-5441c1da9cdf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19257290-6646-4982-a485-5441c1da9cdf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "t0nrv3hMG56M",
        "outputId": "9bd67082-5ad2-4326-dbc9-eac8c6a326c5"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation and Confusion Matrix"
      ],
      "metadata": {
        "id": "fswZ3mbHHCXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as skm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "yZ7G-cXnHDtk"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_val = np.concatenate(y_pred_val, axis=0)\n",
        "y_pred_val = np.argmax(y_pred_val, axis=1).flatten()\n",
        "\n",
        "y_true_val = np.concatenate(y_true_val, axis=0)\n",
        "# y_true_val = np.argmax(y_true_val, axis=1).flatten()\n",
        "# y_pred = np.concatenate((y_pred_train, y_pred_val), axis=None)\n",
        "\n",
        "print(len(y_pred_val))\n",
        "print(len(y_true_val))\n",
        "cm = skm.multilabel_confusion_matrix(y_true_val, y_pred_val)\n",
        "print(cm)\n",
        "print( skm.classification_report(y_true_val, y_pred_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahAr0HFxHI5O",
        "outputId": "b4f228a7-288c-49f2-839e-94c4d7927ba7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122\n",
            "122\n",
            "[[[ 70   6]\n",
            "  [  4  42]]\n",
            "\n",
            " [[ 48   8]\n",
            "  [  6  60]]\n",
            "\n",
            " [[111   1]\n",
            "  [  5   5]]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.89        46\n",
            "           1       0.88      0.91      0.90        66\n",
            "           2       0.83      0.50      0.62        10\n",
            "\n",
            "    accuracy                           0.88       122\n",
            "   macro avg       0.86      0.77      0.80       122\n",
            "weighted avg       0.88      0.88      0.87       122\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "f, ax = plt.subplots(figsize=(8,5))\n",
        "sns.heatmap(confusion_matrix(y_true_val, y_pred_val), annot=True, fmt=\".0f\", ax=ax)\n",
        "plt.xlabel(\"y_head\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "OiOzFI88HLwT",
        "outputId": "70969848-317f-433b-af22-ff7a286c806b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test with Test datasets (Unseen unlabeled)"
      ],
      "metadata": {
        "id": "hADJtLo2rqXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = unlabeled.tweet.values\n"
      ],
      "metadata": {
        "id": "UqvtQIMBsY87"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 70,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Oe9XTiurs1A",
        "outputId": "28dedb28-802d-4793-961e-defd105abe7d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Jumlah batch :', len(prediction_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfPaIUsrtdh0",
        "outputId": "5d8e670c-006b-41f0-8fc3-61cc577f9fde"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah batch : 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions = []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "\n",
        "print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpZK4WX_tlJy",
        "outputId": "7bbe8ff9-5d2b-467e-91da-ec2772a3edc1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 348 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsspVwXWtsU8",
        "outputId": "81ee573c-9e94-48d5-c374-5324ec3168c1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11,)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.concatenate(predictions, axis=0)"
      ],
      "metadata": {
        "id": "NQgkeHCKtvzi"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_result = pd.DataFrame(predictions, columns=['negatif', 'netral', 'positif'])"
      ],
      "metadata": {
        "id": "q4UHrQCEtx91"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfhasilpredict = data_result.eq(data_result.where(data_result != 0).max(1), axis=0).astype(int)\n",
        "dfhasilpredict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dr8XI4Mrt5PK",
        "outputId": "4a267aca-ba9c-4d55-9a62-9c15e92c4491"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     negatif  netral  positif\n",
              "0          1       0        0\n",
              "1          1       0        0\n",
              "2          0       1        0\n",
              "3          1       0        0\n",
              "4          0       1        0\n",
              "..       ...     ...      ...\n",
              "343        0       1        0\n",
              "344        1       0        0\n",
              "345        0       1        0\n",
              "346        1       0        0\n",
              "347        1       0        0\n",
              "\n",
              "[348 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9887add-d94d-46e9-a9e8-4b79f4536dd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negatif</th>\n",
              "      <th>netral</th>\n",
              "      <th>positif</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>348 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9887add-d94d-46e9-a9e8-4b79f4536dd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9887add-d94d-46e9-a9e8-4b79f4536dd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9887add-d94d-46e9-a9e8-4b79f4536dd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finalresult = pd.concat([unlabeled, dfhasilpredict], axis=1, sort=False)"
      ],
      "metadata": {
        "id": "QxkeIb7suN93"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalresult"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "UTUDTTg3uX1q",
        "outputId": "9d99a334-8b70-4e28-c7e0-5cd8a7cd96ce"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                              tweet  negatif  \\\n",
              "0             0  data sim card bocor media main blender menkomi...        1   \n",
              "1             1  data sim card bocor media main blender menkomi...        1   \n",
              "2             2  kemenkominfo investigasi bocor miliar data sim...        0   \n",
              "3             3  kan kalian bikin atur beli sim card pakai nik ...        1   \n",
              "4             4   kominfo bocor miliar data sim card olah pahlawan        0   \n",
              "..          ...                                                ...      ...   \n",
              "343         343  miliar data daftar kartu sim telepon indonesia...        0   \n",
              "344         344  buat regulasi daftar data kartu sim telepon ka...        1   \n",
              "345         345  kait duga data sim bocor nyata tri kominfo mil...        0   \n",
              "346         346  benar kominfo data sim bocor data duli lindung...        1   \n",
              "347         347  milliar data registrasi kartu sim bocor lalu a...        1   \n",
              "\n",
              "     netral  positif  \n",
              "0         0        0  \n",
              "1         0        0  \n",
              "2         1        0  \n",
              "3         0        0  \n",
              "4         1        0  \n",
              "..      ...      ...  \n",
              "343       1        0  \n",
              "344       0        0  \n",
              "345       1        0  \n",
              "346       0        0  \n",
              "347       0        0  \n",
              "\n",
              "[348 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c496e88-a721-41d3-858f-d65020f59aa3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>negatif</th>\n",
              "      <th>netral</th>\n",
              "      <th>positif</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>data sim card bocor media main blender menkomi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>data sim card bocor media main blender menkomi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>kemenkominfo investigasi bocor miliar data sim...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>kan kalian bikin atur beli sim card pakai nik ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>kominfo bocor miliar data sim card olah pahlawan</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>343</td>\n",
              "      <td>miliar data daftar kartu sim telepon indonesia...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>344</td>\n",
              "      <td>buat regulasi daftar data kartu sim telepon ka...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>345</td>\n",
              "      <td>kait duga data sim bocor nyata tri kominfo mil...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>346</td>\n",
              "      <td>benar kominfo data sim bocor data duli lindung...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>347</td>\n",
              "      <td>milliar data registrasi kartu sim bocor lalu a...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>348 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c496e88-a721-41d3-858f-d65020f59aa3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c496e88-a721-41d3-858f-d65020f59aa3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c496e88-a721-41d3-858f-d65020f59aa3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finalresult.to_excel(\"final_pred.xlsx\")"
      ],
      "metadata": {
        "id": "pzFiMtUbubOZ"
      },
      "execution_count": 76,
      "outputs": []
    }
  ]
}